{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# ðŸŽ­ Futuristic Live Emotion Detection System\n",
        "\n",
        "## Advanced Real-Time Emotion Recognition with AI-Powered Analytics\n",
        "\n",
        "This notebook provides a comprehensive, futuristic interface for live emotion detection using deep learning models.\n",
        "\n",
        "### Features:\n",
        "- ðŸš€ **Real-time emotion detection** from webcam\n",
        "- ðŸ“Š **Advanced analytics dashboard**\n",
        "- ðŸŽ¨ **Futuristic UI design** with animations\n",
        "- ðŸ“ˆ **Performance monitoring** and statistics\n",
        "- ðŸ”¬ **Emotion trend analysis**\n",
        "- ðŸ’¾ **Data export capabilities**\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Import all necessary libraries\n",
        "import cv2\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import model_from_json\n",
        "import time\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import pandas as pd\n",
        "from collections import deque\n",
        "import threading\n",
        "import json\n",
        "from datetime import datetime\n",
        "import os\n",
        "from IPython.display import display, clear_output\n",
        "import ipywidgets as widgets\n",
        "from matplotlib.animation import FuncAnimation\n",
        "\n",
        "# Set style for futuristic plots\n",
        "plt.style.use('dark_background')\n",
        "sns.set_style(\"darkgrid\")\n",
        "\n",
        "print(\"ðŸš€ Futuristic Emotion Detection System Initialized!\")\n",
        "print(\"ðŸ“¦ All dependencies loaded successfully\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ðŸ§  AI Model Configuration\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class FuturisticEmotionDetector:\n",
        "    def __init__(self, model_json_path, model_weights_path):\n",
        "        \"\"\"\n",
        "        Initialize the futuristic emotion detector\n",
        "        \"\"\"\n",
        "        # Load model architecture\n",
        "        with open(model_json_path, 'r') as json_file:\n",
        "            loaded_model_json = json_file.read()\n",
        "        \n",
        "        self.model = model_from_json(loaded_model_json)\n",
        "        self.model.load_weights(model_weights_path)\n",
        "        self.model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "        \n",
        "        # Emotion configuration\n",
        "        self.emotion_labels = [\"ðŸ˜Š Happy\", \"ðŸ˜¢ Sad\", \"ðŸ˜ Neutral\"]\n",
        "        self.emotion_colors = [(0, 255, 100), (100, 100, 255), (255, 255, 100)]\n",
        "        \n",
        "        # Initialize face detection\n",
        "        self.face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')\n",
        "        \n",
        "        # Advanced statistics tracking\n",
        "        self.session_start_time = time.time()\n",
        "        self.total_detections = 0\n",
        "        self.emotion_counts = {emotion: 0 for emotion in self.emotion_labels}\n",
        "        self.emotion_history = deque(maxlen=100)  # Last 100 detections\n",
        "        self.confidence_history = deque(maxlen=100)\n",
        "        self.frame_count = 0\n",
        "        self.fps_history = deque(maxlen=30)\n",
        "        self.current_fps = 0\n",
        "        self.dominant_emotion = \"N/A\"\n",
        "        self.dominant_confidence = 0.0\n",
        "        \n",
        "        # Performance metrics\n",
        "        self.avg_confidence = 0.0\n",
        "        self.detection_rate = 0.0\n",
        "        \n",
        "        print(\"âœ… AI Model loaded successfully!\")\n",
        "        print(f\"ðŸŽ¯ Detecting {len(self.emotion_labels)} emotions\")\n",
        "    \n",
        "    def preprocess_face(self, face_roi):\n",
        "        \"\"\"Advanced face preprocessing\"\"\"\n",
        "        if len(face_roi.shape) == 3:\n",
        "            face_roi = cv2.cvtColor(face_roi, cv2.COLOR_BGR2GRAY)\n",
        "        \n",
        "        # Enhanced preprocessing\n",
        "        face_resized = cv2.resize(face_roi, (48, 48))\n",
        "        face_normalized = face_resized.astype('float32') / 255.0\n",
        "        \n",
        "        # Apply slight augmentation for robustness\n",
        "        if np.random.random() > 0.5:\n",
        "            face_normalized = cv2.flip(face_normalized, 1)\n",
        "        \n",
        "        return face_normalized.reshape(1, 48, 48, 1)\n",
        "    \n",
        "    def predict_emotion(self, face_roi):\n",
        "        \"\"\"Advanced emotion prediction with confidence analysis\"\"\"\n",
        "        processed_face = self.preprocess_face(face_roi)\n",
        "        predictions = self.model.predict(processed_face, verbose=0)\n",
        "        \n",
        "        emotion_idx = np.argmax(predictions[0])\n",
        "        confidence = predictions[0][emotion_idx]\n",
        "        emotion_label = self.emotion_labels[emotion_idx]\n",
        "        \n",
        "        # Update statistics\n",
        "        self.total_detections += 1\n",
        "        self.emotion_counts[emotion_label] += 1\n",
        "        self.emotion_history.append(emotion_label)\n",
        "        self.confidence_history.append(confidence)\n",
        "        \n",
        "        # Update dominant emotion\n",
        "        if confidence > self.dominant_confidence:\n",
        "            self.dominant_emotion = emotion_label\n",
        "            self.dominant_confidence = confidence\n",
        "        \n",
        "        # Calculate average confidence\n",
        "        self.avg_confidence = np.mean(list(self.confidence_history))\n",
        "        \n",
        "        return emotion_label, confidence, predictions[0]\n",
        "    \n",
        "    def create_futuristic_overlay(self, frame):\n",
        "        \"\"\"Create advanced futuristic UI overlay with scalable design\"\"\"\n",
        "        height, width = frame.shape[:2]\n",
        "        \n",
        "        # Calculate scale factors for fullscreen\n",
        "        scale_factor = width / 1920.0  # Base resolution\n",
        "        \n",
        "        # Create overlay with gradient effect\n",
        "        overlay = frame.copy()\n",
        "        \n",
        "        # Main dashboard area (scales with screen)\n",
        "        dashboard_height = int(250 * scale_factor)\n",
        "        cv2.rectangle(overlay, (0, 0), (width, dashboard_height), (0, 0, 0), -1)\n",
        "        \n",
        "        # Add gradient effect\n",
        "        for i in range(dashboard_height):\n",
        "            alpha = 0.8 - (i / dashboard_height) * 0.3\n",
        "            color = (int(20 * alpha), int(50 * alpha), int(100 * alpha))\n",
        "            cv2.line(overlay, (0, i), (width, i), color, 1)\n",
        "        \n",
        "        # Blend overlay\n",
        "        cv2.addWeighted(overlay, 0.7, frame, 0.3, 0, frame)\n",
        "        \n",
        "        # Calculate session time\n",
        "        session_time = time.time() - self.session_start_time\n",
        "        minutes = int(session_time // 60)\n",
        "        seconds = int(session_time % 60)\n",
        "        \n",
        "        # Futuristic title with glow effect (scaled)\n",
        "        title_size = 1.2 * scale_factor\n",
        "        title_thickness = int(3 * scale_factor)\n",
        "        title_text = \"NEURAL EMOTION ANALYZER\"\n",
        "        title_x = int(20 * scale_factor)\n",
        "        title_y = int(40 * scale_factor)\n",
        "        cv2.putText(frame, title_text, (title_x, title_y), cv2.FONT_HERSHEY_SIMPLEX, title_size, (0, 255, 255), title_thickness)\n",
        "        cv2.putText(frame, title_text, (title_x, title_y), cv2.FONT_HERSHEY_SIMPLEX, title_size, (255, 255, 255), int(title_thickness * 0.67))\n",
        "        \n",
        "        # System status indicators (scaled)\n",
        "        font_scale = 0.6 * scale_factor\n",
        "        line_height = int(25 * scale_factor)\n",
        "        status_y = int(80 * scale_factor)\n",
        "        status_x = int(20 * scale_factor)\n",
        "        \n",
        "        cv2.putText(frame, f\"SYSTEM STATUS: ONLINE\", (status_x, status_y), cv2.FONT_HERSHEY_SIMPLEX, font_scale, (0, 255, 0), int(2 * scale_factor))\n",
        "        cv2.putText(frame, f\"SESSION TIME: {minutes:02d}:{seconds:02d}\", (status_x, status_y + line_height), cv2.FONT_HERSHEY_SIMPLEX, font_scale, (255, 255, 255), int(1 * scale_factor))\n",
        "        cv2.putText(frame, f\"DETECTIONS: {self.total_detections}\", (status_x, status_y + line_height * 2), cv2.FONT_HERSHEY_SIMPLEX, font_scale, (255, 255, 255), int(1 * scale_factor))\n",
        "        cv2.putText(frame, f\"FPS: {self.current_fps:.1f}\", (status_x, status_y + line_height * 3), cv2.FONT_HERSHEY_SIMPLEX, font_scale, (255, 255, 255), int(1 * scale_factor))\n",
        "        \n",
        "        # Dominant emotion display\n",
        "        dominant_color = (0, 255, 0) if self.dominant_emotion != \"N/A\" else (255, 255, 255)\n",
        "        cv2.putText(frame, f\"DOMINANT: {self.dominant_emotion}\", (status_x, status_y + line_height * 4), cv2.FONT_HERSHEY_SIMPLEX, 0.7 * scale_factor, dominant_color, int(2 * scale_factor))\n",
        "        cv2.putText(frame, f\"CONFIDENCE: {self.dominant_confidence:.1%}\", (status_x, status_y + line_height * 5), cv2.FONT_HERSHEY_SIMPLEX, font_scale, (255, 255, 255), int(1 * scale_factor))\n",
        "        \n",
        "        # Performance metrics\n",
        "        cv2.putText(frame, f\"AVG CONFIDENCE: {self.avg_confidence:.1%}\", (status_x, status_y + line_height * 6), cv2.FONT_HERSHEY_SIMPLEX, 0.5 * scale_factor, (200, 200, 200), int(1 * scale_factor))\n",
        "        \n",
        "        # Right side analytics (scaled)\n",
        "        analytics_x = int((width - 300) * scale_factor)\n",
        "        cv2.putText(frame, \"EMOTION ANALYTICS\", (analytics_x, title_y), cv2.FONT_HERSHEY_SIMPLEX, 0.8 * scale_factor, (255, 100, 100), int(2 * scale_factor))\n",
        "        \n",
        "        y_offset = status_y\n",
        "        for i, (emotion, count) in enumerate(self.emotion_counts.items()):\n",
        "            percentage = (count / max(self.total_detections, 1)) * 100\n",
        "            color = self.emotion_colors[i]\n",
        "            cv2.putText(frame, f\"{emotion}: {count} ({percentage:.1f}%)\", \n",
        "                       (analytics_x, y_offset), cv2.FONT_HERSHEY_SIMPLEX, 0.5 * scale_factor, color, int(1 * scale_factor))\n",
        "            \n",
        "            # Progress bar (scaled)\n",
        "            bar_width = int(percentage * 2 * scale_factor)\n",
        "            bar_height = int(5 * scale_factor)\n",
        "            cv2.rectangle(frame, (analytics_x, y_offset + int(15 * scale_factor)), \n",
        "                         (analytics_x + bar_width, y_offset + int(15 * scale_factor) + bar_height), color, -1)\n",
        "            cv2.rectangle(frame, (analytics_x, y_offset + int(15 * scale_factor)), \n",
        "                         (analytics_x + int(200 * scale_factor), y_offset + int(15 * scale_factor) + bar_height), (255, 255, 255), int(1 * scale_factor))\n",
        "            \n",
        "            y_offset += int(40 * scale_factor)\n",
        "        \n",
        "        # Add futuristic border effects\n",
        "        self.add_futuristic_borders(frame)\n",
        "        \n",
        "        return frame\n",
        "    \n",
        "    def add_futuristic_borders(self, frame):\n",
        "        \"\"\"Add futuristic border effects (scalable for fullscreen)\"\"\"\n",
        "        height, width = frame.shape[:2]\n",
        "        scale_factor = width / 1920.0\n",
        "        \n",
        "        # Corner brackets (scaled)\n",
        "        bracket_size = int(30 * scale_factor)\n",
        "        thickness = max(int(3 * scale_factor), 1)\n",
        "        color = (0, 255, 255)\n",
        "        margin = int(10 * scale_factor)\n",
        "        \n",
        "        # Top-left bracket\n",
        "        cv2.line(frame, (margin, margin), (bracket_size + margin, margin), color, thickness)\n",
        "        cv2.line(frame, (margin, margin), (margin, bracket_size + margin), color, thickness)\n",
        "        \n",
        "        # Top-right bracket\n",
        "        cv2.line(frame, (width - bracket_size - margin, margin), (width - margin, margin), color, thickness)\n",
        "        cv2.line(frame, (width - margin, margin), (width - margin, bracket_size + margin), color, thickness)\n",
        "        \n",
        "        # Bottom-left bracket\n",
        "        cv2.line(frame, (margin, height - bracket_size - margin), (margin, height - margin), color, thickness)\n",
        "        cv2.line(frame, (margin, height - margin), (bracket_size + margin, height - margin), color, thickness)\n",
        "        \n",
        "        # Bottom-right bracket\n",
        "        cv2.line(frame, (width - margin, height - bracket_size - margin), (width - margin, height - margin), color, thickness)\n",
        "        cv2.line(frame, (width - bracket_size - margin, height - margin), (width - margin, height - margin), color, thickness)\n",
        "        \n",
        "        # Scanning line effect\n",
        "        scan_y = int((time.time() * 2) % height)\n",
        "        cv2.line(frame, (0, scan_y), (width, scan_y), (0, 255, 0), max(1, int(scale_factor)))\n",
        "    \n",
        "    def draw_advanced_face_info(self, frame, emotion, confidence, predictions, x, y, w, h):\n",
        "        \"\"\"Draw advanced face information with futuristic styling (fullscreen scalable)\"\"\"\n",
        "        height, width = frame.shape[:2]\n",
        "        scale_factor = width / 1920.0\n",
        "        \n",
        "        # Enhanced face rectangle with glow effect (scaled)\n",
        "        glow_thickness = max(int(3 * scale_factor), 1)\n",
        "        cv2.rectangle(frame, (x-int(2*scale_factor), y-int(2*scale_factor)), \n",
        "                     (x+w+int(2*scale_factor), y+h+int(2*scale_factor)), (0, 255, 255), glow_thickness)\n",
        "        cv2.rectangle(frame, (x, y), (x+w, y+h), (0, 255, 0), max(int(2 * scale_factor), 1))\n",
        "        \n",
        "        # Emotion label with background (scaled)\n",
        "        label_bg_height = int(40 * scale_factor)\n",
        "        cv2.rectangle(frame, (x, y-label_bg_height), (x+w, y), (0, 0, 0), -1)\n",
        "        font_size = 0.7 * scale_factor\n",
        "        cv2.putText(frame, emotion, (x+int(5*scale_factor), y-int(10*scale_factor)), \n",
        "                   cv2.FONT_HERSHEY_SIMPLEX, font_size, (0, 255, 0), max(int(2 * scale_factor), 1))\n",
        "        \n",
        "        # Confidence bar (scaled)\n",
        "        conf_bar_width = int(confidence * w)\n",
        "        bar_y = y + h + int(5 * scale_factor)\n",
        "        bar_height = int(10 * scale_factor)\n",
        "        cv2.rectangle(frame, (x, bar_y), (x+conf_bar_width, bar_y+bar_height), (0, 255, 0), -1)\n",
        "        cv2.rectangle(frame, (x, bar_y), (x+w, bar_y+bar_height), (255, 255, 255), max(int(1 * scale_factor), 1))\n",
        "        \n",
        "        # Detailed predictions (scaled)\n",
        "        y_offset = y + h + int(25 * scale_factor)\n",
        "        for i, (emotion_label, pred_conf) in enumerate(zip(self.emotion_labels, predictions)):\n",
        "            color = self.emotion_colors[i]\n",
        "            cv2.putText(frame, f\"{emotion_label}: {pred_conf:.2f}\", \n",
        "                       (x, y_offset), cv2.FONT_HERSHEY_SIMPLEX, 0.4 * scale_factor, color, max(int(1 * scale_factor), 1))\n",
        "            y_offset += int(15 * scale_factor)\n",
        "        \n",
        "        # Location info (scaled)\n",
        "        cv2.putText(frame, f\"POS: ({x},{y}) SIZE: {w}x{h}\", \n",
        "                   (x, y_offset), cv2.FONT_HERSHEY_SIMPLEX, 0.4 * scale_factor, (200, 200, 200), max(int(1 * scale_factor), 1))\n",
        "    \n",
        "    def get_screen_resolution(self):\n",
        "        \"\"\"Get screen resolution (cross-platform)\"\"\"\n",
        "        try:\n",
        "            import tkinter as tk\n",
        "            root = tk.Tk()\n",
        "            screen_width = root.winfo_screenwidth()\n",
        "            screen_height = root.winfo_screenheight()\n",
        "            root.destroy()\n",
        "            return screen_width, screen_height\n",
        "        except:\n",
        "            # Fallback to common resolutions if tkinter not available\n",
        "            return 1920, 1080\n",
        "    \n",
        "    def run_futuristic_detection(self, camera_index=0):\n",
        "        \"\"\"Run the futuristic emotion detection system in FULLSCREEN mode\"\"\"\n",
        "        cap = cv2.VideoCapture(camera_index)\n",
        "        \n",
        "        if not cap.isOpened():\n",
        "            print(\"âŒ Error: Could not access camera!\")\n",
        "            return\n",
        "        \n",
        "        # Get screen resolution for fullscreen\n",
        "        screen_width, screen_height = self.get_screen_resolution()\n",
        "        print(f\"ðŸ“º Screen Resolution: {screen_width}x{screen_height}\")\n",
        "        \n",
        "        print(\"ðŸš€ Starting Futuristic Emotion Detection System...\")\n",
        "        print(\"ðŸ–¥ï¸ FULLSCREEN MODE ACTIVATED\")\n",
        "        print(\"ðŸ“ Controls: 'q'=quit, 's'=save, 'r'=reset, 'a'=analytics, 'f'=toggle fullscreen\")\n",
        "        \n",
        "        # Set camera to maximum supported resolution\n",
        "        cap.set(cv2.CAP_PROP_FRAME_WIDTH, screen_width)\n",
        "        cap.set(cv2.CAP_PROP_FRAME_HEIGHT, screen_height)\n",
        "        cap.set(cv2.CAP_PROP_FPS, 30)\n",
        "        \n",
        "        # Create window and set to fullscreen\n",
        "        window_name = 'Futuristic Emotion Detection System'\n",
        "        cv2.namedWindow(window_name, cv2.WINDOW_NORMAL)\n",
        "        cv2.setWindowProperty(window_name, cv2.WND_PROP_FULLSCREEN, cv2.WINDOW_FULLSCREEN)\n",
        "        \n",
        "        fullscreen_mode = True\n",
        "        \n",
        "        try:\n",
        "            while True:\n",
        "                ret, frame = cap.read()\n",
        "                if not ret:\n",
        "                    break\n",
        "                \n",
        "                # Mirror effect\n",
        "                frame = cv2.flip(frame, 1)\n",
        "                \n",
        "                # Resize frame to screen resolution if needed\n",
        "                current_height, current_width = frame.shape[:2]\n",
        "                if current_width != screen_width or current_height != screen_height:\n",
        "                    frame = cv2.resize(frame, (screen_width, screen_height), interpolation=cv2.INTER_LINEAR)\n",
        "                \n",
        "                # Face detection\n",
        "                gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
        "                faces = self.face_cascade.detectMultiScale(\n",
        "                    gray, scaleFactor=1.1, minNeighbors=5, minSize=(30, 30)\n",
        "                )\n",
        "                \n",
        "                # Process faces\n",
        "                for (x, y, w, h) in faces:\n",
        "                    face_roi = gray[y:y+h, x:x+w]\n",
        "                    emotion, confidence, predictions = self.predict_emotion(face_roi)\n",
        "                    self.draw_advanced_face_info(frame, emotion, confidence, predictions, x, y, w, h)\n",
        "                \n",
        "                # Update FPS\n",
        "                self.frame_count += 1\n",
        "                if self.frame_count % 30 == 0:\n",
        "                    fps_end_time = time.time()\n",
        "                    self.current_fps = 30 / (fps_end_time - self.fps_start_time)\n",
        "                    self.fps_start_time = fps_end_time\n",
        "                    self.fps_history.append(self.current_fps)\n",
        "                \n",
        "                # Apply futuristic overlay (automatically scales for fullscreen)\n",
        "                frame = self.create_futuristic_overlay(frame)\n",
        "                \n",
        "                # Instructions (scaled for fullscreen)\n",
        "                scale_factor = screen_width / 1920.0\n",
        "                instruction_text = \"NEURAL SYSTEM ACTIVE - PRESS 'Q' TO TERMINATE | 'F' TO TOGGLE FULLSCREEN\"\n",
        "                cv2.putText(frame, instruction_text, \n",
        "                           (int(10 * scale_factor), int(screen_height - 20 * scale_factor)), \n",
        "                           cv2.FONT_HERSHEY_SIMPLEX, 0.6 * scale_factor, (255, 255, 255), int(2 * scale_factor))\n",
        "                \n",
        "                # Display\n",
        "                cv2.imshow(window_name, frame)\n",
        "                \n",
        "                # Controls\n",
        "                key = cv2.waitKey(1) & 0xFF\n",
        "                if key == ord('q'):\n",
        "                    break\n",
        "                elif key == ord('f'):\n",
        "                    # Toggle fullscreen\n",
        "                    fullscreen_mode = not fullscreen_mode\n",
        "                    if fullscreen_mode:\n",
        "                        cv2.setWindowProperty(window_name, cv2.WND_PROP_FULLSCREEN, cv2.WINDOW_FULLSCREEN)\n",
        "                        print(\"ðŸ–¥ï¸ Fullscreen mode ON\")\n",
        "                    else:\n",
        "                        cv2.setWindowProperty(window_name, cv2.WND_PROP_FULLSCREEN, cv2.WINDOW_NORMAL)\n",
        "                        cv2.resizeWindow(window_name, 1280, 720)\n",
        "                        print(\"ðŸªŸ Windowed mode\")\n",
        "                elif key == ord('s'):\n",
        "                    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
        "                    filename = f\"futuristic_emotion_{timestamp}.jpg\"\n",
        "                    cv2.imwrite(filename, frame)\n",
        "                    print(f\"ðŸ“¸ Screenshot saved: {filename}\")\n",
        "                elif key == ord('r'):\n",
        "                    self.reset_statistics()\n",
        "                elif key == ord('a'):\n",
        "                    self.show_analytics()\n",
        "        \n",
        "        except KeyboardInterrupt:\n",
        "            print(\"\\nðŸ›‘ System terminated by user\")\n",
        "        \n",
        "        finally:\n",
        "            cap.release()\n",
        "            cv2.destroyAllWindows()\n",
        "            print(\"âœ… Neural system shutdown complete\")\n",
        "    \n",
        "    def reset_statistics(self):\n",
        "        \"\"\"Reset all statistics\"\"\"\n",
        "        self.total_detections = 0\n",
        "        self.emotion_counts = {emotion: 0 for emotion in self.emotion_labels}\n",
        "        self.emotion_history.clear()\n",
        "        self.confidence_history.clear()\n",
        "        self.dominant_emotion = \"N/A\"\n",
        "        self.dominant_confidence = 0.0\n",
        "        self.session_start_time = time.time()\n",
        "        print(\"ðŸ”„ Statistics reset!\")\n",
        "    \n",
        "    def show_analytics(self):\n",
        "        \"\"\"Display advanced analytics\"\"\"\n",
        "        print(\"\\nðŸ“Š ADVANCED ANALYTICS\")\n",
        "        print(\"=\" * 50)\n",
        "        print(f\"Total Detections: {self.total_detections}\")\n",
        "        print(f\"Average Confidence: {self.avg_confidence:.2%}\")\n",
        "        print(f\"Current FPS: {self.current_fps:.1f}\")\n",
        "        print(f\"Dominant Emotion: {self.dominant_emotion}\")\n",
        "        print(\"\\nEmotion Distribution:\")\n",
        "        for emotion, count in self.emotion_counts.items():\n",
        "            percentage = (count / max(self.total_detections, 1)) * 100\n",
        "            print(f\"  {emotion}: {count} ({percentage:.1f}%)\")\n",
        "\n",
        "# Initialize the detector\n",
        "detector = FuturisticEmotionDetector(\"model.json\", \"model.h5\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ðŸ“Š Real-Time Analytics Dashboard\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create interactive analytics dashboard\n",
        "def create_analytics_dashboard():\n",
        "    \"\"\"Create a comprehensive analytics dashboard\"\"\"\n",
        "    fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
        "    fig.suptitle('ðŸŽ­ Futuristic Emotion Analytics Dashboard', fontsize=16, color='cyan')\n",
        "    \n",
        "    # Emotion distribution pie chart\n",
        "    if detector.total_detections > 0:\n",
        "        emotions = list(detector.emotion_counts.keys())\n",
        "        counts = list(detector.emotion_counts.values())\n",
        "        colors = ['#00ff64', '#6464ff', '#ffff64']\n",
        "        \n",
        "        axes[0, 0].pie(counts, labels=emotions, colors=colors, autopct='%1.1f%%', startangle=90)\n",
        "        axes[0, 0].set_title('Emotion Distribution', color='white', fontsize=12)\n",
        "        \n",
        "        # Confidence trend\n",
        "        if len(detector.confidence_history) > 1:\n",
        "            axes[0, 1].plot(list(detector.confidence_history), color='cyan', linewidth=2)\n",
        "            axes[0, 1].set_title('Confidence Trend', color='white', fontsize=12)\n",
        "            axes[0, 1].set_ylabel('Confidence')\n",
        "            axes[0, 1].grid(True, alpha=0.3)\n",
        "        \n",
        "        # FPS performance\n",
        "        if len(detector.fps_history) > 1:\n",
        "            axes[1, 0].plot(list(detector.fps_history), color='lime', linewidth=2)\n",
        "            axes[1, 0].set_title('Performance (FPS)', color='white', fontsize=12)\n",
        "            axes[1, 0].set_ylabel('FPS')\n",
        "            axes[1, 0].grid(True, alpha=0.3)\n",
        "        \n",
        "        # Emotion timeline\n",
        "        if len(detector.emotion_history) > 1:\n",
        "            emotion_numeric = []\n",
        "            for emotion in detector.emotion_history:\n",
        "                emotion_numeric.append(detector.emotion_labels.index(emotion))\n",
        "            \n",
        "            axes[1, 1].plot(emotion_numeric, color='magenta', linewidth=2, marker='o', markersize=3)\n",
        "            axes[1, 1].set_title('Emotion Timeline', color='white', fontsize=12)\n",
        "            axes[1, 1].set_ylabel('Emotion Index')\n",
        "            axes[1, 1].set_yticks(range(len(detector.emotion_labels)))\n",
        "            axes[1, 1].set_yticklabels(detector.emotion_labels)\n",
        "            axes[1, 1].grid(True, alpha=0.3)\n",
        "    \n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "# Create the dashboard\n",
        "create_analytics_dashboard()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ðŸŽ® Interactive Controls\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create interactive control panel\n",
        "from IPython.display import display\n",
        "import ipywidgets as widgets\n",
        "\n",
        "# Control buttons\n",
        "start_button = widgets.Button(\n",
        "    description='ðŸš€ Start Detection',\n",
        "    button_style='success',\n",
        "    layout=widgets.Layout(width='200px', height='50px')\n",
        ")\n",
        "\n",
        "analytics_button = widgets.Button(\n",
        "    description='ðŸ“Š Show Analytics',\n",
        "    button_style='info',\n",
        "    layout=widgets.Layout(width='200px', height='50px')\n",
        ")\n",
        "\n",
        "reset_button = widgets.Button(\n",
        "    description='ðŸ”„ Reset Stats',\n",
        "    button_style='warning',\n",
        "    layout=widgets.Layout(width='200px', height='50px')\n",
        ")\n",
        "\n",
        "export_button = widgets.Button(\n",
        "    description='ðŸ’¾ Export Data',\n",
        "    button_style='primary',\n",
        "    layout=widgets.Layout(width='200px', height='50px')\n",
        ")\n",
        "\n",
        "# Status display\n",
        "status_text = widgets.HTML(\n",
        "    value=\"<h3>ðŸŽ­ Futuristic Emotion Detection System</h3><p>Ready to initialize neural analysis...</p>\",\n",
        "    layout=widgets.Layout(width='100%')\n",
        ")\n",
        "\n",
        "def on_start_clicked(b):\n",
        "    status_text.value = \"<h3>ðŸš€ System Starting...</h3><p>Initializing camera and neural networks...</p>\"\n",
        "    detector.run_futuristic_detection()\n",
        "\n",
        "def on_analytics_clicked(b):\n",
        "    status_text.value = \"<h3>ðŸ“Š Generating Analytics...</h3><p>Processing neural data...</p>\"\n",
        "    create_analytics_dashboard()\n",
        "\n",
        "def on_reset_clicked(b):\n",
        "    detector.reset_statistics()\n",
        "    status_text.value = \"<h3>ðŸ”„ Statistics Reset</h3><p>All neural data cleared. Ready for new session.</p>\"\n",
        "\n",
        "def on_export_clicked(b):\n",
        "    # Export data to JSON\n",
        "    export_data = {\n",
        "        'session_info': {\n",
        "            'start_time': detector.session_start_time,\n",
        "            'total_detections': detector.total_detections,\n",
        "            'avg_confidence': detector.avg_confidence\n",
        "        },\n",
        "        'emotion_counts': detector.emotion_counts,\n",
        "        'emotion_history': list(detector.emotion_history),\n",
        "        'confidence_history': list(detector.confidence_history)\n",
        "    }\n",
        "    \n",
        "    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
        "    filename = f\"emotion_data_{timestamp}.json\"\n",
        "    \n",
        "    with open(filename, 'w') as f:\n",
        "        json.dump(export_data, f, indent=2)\n",
        "    \n",
        "    status_text.value = f\"<h3>ðŸ’¾ Data Exported</h3><p>Saved to: {filename}</p>\"\n",
        "\n",
        "# Connect button events\n",
        "start_button.on_click(on_start_clicked)\n",
        "analytics_button.on_click(on_analytics_clicked)\n",
        "reset_button.on_click(on_reset_clicked)\n",
        "export_button.on_click(on_export_clicked)\n",
        "\n",
        "# Display control panel\n",
        "control_panel = widgets.VBox([\n",
        "    status_text,\n",
        "    widgets.HBox([start_button, analytics_button]),\n",
        "    widgets.HBox([reset_button, export_button])\n",
        "])\n",
        "\n",
        "display(control_panel)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ðŸ”¬ Advanced Features\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Advanced emotion analysis functions\n",
        "def analyze_emotion_patterns():\n",
        "    \"\"\"Analyze emotion patterns and trends\"\"\"\n",
        "    if len(detector.emotion_history) < 10:\n",
        "        print(\"âš ï¸ Insufficient data for pattern analysis. Run detection first.\")\n",
        "        return\n",
        "    \n",
        "    print(\"ðŸ”¬ EMOTION PATTERN ANALYSIS\")\n",
        "    print(\"=\" * 50)\n",
        "    \n",
        "    # Calculate emotion transitions\n",
        "    transitions = {}\n",
        "    for i in range(len(detector.emotion_history) - 1):\n",
        "        current = detector.emotion_history[i]\n",
        "        next_emotion = detector.emotion_history[i + 1]\n",
        "        transition = f\"{current} â†’ {next_emotion}\"\n",
        "        transitions[transition] = transitions.get(transition, 0) + 1\n",
        "    \n",
        "    print(\"\\nMost Common Emotion Transitions:\")\n",
        "    for transition, count in sorted(transitions.items(), key=lambda x: x[1], reverse=True)[:5]:\n",
        "        print(f\"  {transition}: {count} times\")\n",
        "    \n",
        "    # Calculate stability\n",
        "    stable_periods = 0\n",
        "    for i in range(len(detector.emotion_history) - 2):\n",
        "        if detector.emotion_history[i] == detector.emotion_history[i + 1] == detector.emotion_history[i + 2]:\n",
        "            stable_periods += 1\n",
        "    \n",
        "    stability = (stable_periods / max(len(detector.emotion_history) - 2, 1)) * 100\n",
        "    print(f\"\\nEmotional Stability: {stability:.1f}%\")\n",
        "    \n",
        "    # Confidence analysis\n",
        "    if detector.confidence_history:\n",
        "        avg_conf = np.mean(list(detector.confidence_history))\n",
        "        std_conf = np.std(list(detector.confidence_history))\n",
        "        print(f\"\\nConfidence Statistics:\")\n",
        "        print(f\"  Average: {avg_conf:.3f}\")\n",
        "        print(f\"  Standard Deviation: {std_conf:.3f}\")\n",
        "        print(f\"  Range: {min(detector.confidence_history):.3f} - {max(detector.confidence_history):.3f}\")\n",
        "\n",
        "def create_emotion_heatmap():\n",
        "    \"\"\"Create emotion heatmap visualization\"\"\"\n",
        "    if len(detector.emotion_history) < 20:\n",
        "        print(\"âš ï¸ Insufficient data for heatmap. Need at least 20 detections.\")\n",
        "        return\n",
        "    \n",
        "    # Create emotion matrix\n",
        "    emotion_matrix = np.zeros((len(detector.emotion_labels), len(detector.emotion_labels)))\n",
        "    \n",
        "    for i in range(len(detector.emotion_history) - 1):\n",
        "        current_idx = detector.emotion_labels.index(detector.emotion_history[i])\n",
        "        next_idx = detector.emotion_labels.index(detector.emotion_history[i + 1])\n",
        "        emotion_matrix[current_idx, next_idx] += 1\n",
        "    \n",
        "    # Normalize\n",
        "    emotion_matrix = emotion_matrix / np.sum(emotion_matrix, axis=1, keepdims=True)\n",
        "    emotion_matrix = np.nan_to_num(emotion_matrix)\n",
        "    \n",
        "    # Create heatmap\n",
        "    plt.figure(figsize=(10, 8))\n",
        "    sns.heatmap(emotion_matrix, \n",
        "                xticklabels=detector.emotion_labels,\n",
        "                yticklabels=detector.emotion_labels,\n",
        "                annot=True, \n",
        "                cmap='viridis',\n",
        "                fmt='.2f')\n",
        "    plt.title('ðŸ”¥ Emotion Transition Heatmap', fontsize=16, color='white')\n",
        "    plt.xlabel('Next Emotion', color='white')\n",
        "    plt.ylabel('Current Emotion', color='white')\n",
        "    plt.show()\n",
        "\n",
        "# Display advanced features\n",
        "print(\"ðŸ”¬ Advanced Analysis Functions Available:\")\n",
        "print(\"1. analyze_emotion_patterns() - Analyze emotion transitions and stability\")\n",
        "print(\"2. create_emotion_heatmap() - Visualize emotion transition patterns\")\n",
        "print(\"3. detector.show_analytics() - Display current statistics\")\n",
        "print(\"\\nðŸ’¡ Run these functions after collecting data from live detection!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ðŸš€ Launch the Futuristic System\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Launch the futuristic emotion detection system\n",
        "print(\"ðŸŽ­ FUTURISTIC EMOTION DETECTION SYSTEM\")\n",
        "print(\"=\" * 50)\n",
        "print(\"ðŸš€ Initializing neural networks...\")\n",
        "print(\"ðŸ“¡ Connecting to camera systems...\")\n",
        "print(\"ðŸ”¬ Loading AI models...\")\n",
        "print(\"âœ… System ready for deployment!\")\n",
        "print(\"\\nðŸ“ Instructions:\")\n",
        "print(\"  â€¢ Use the control panel above to start detection\")\n",
        "print(\"  â€¢ Press 'q' to quit, 's' to save, 'r' to reset, 'a' for analytics\")\n",
        "print(\"  â€¢ The system features futuristic UI with real-time analytics\")\n",
        "print(\"  â€¢ All data is tracked and can be exported for analysis\")\n",
        "print(\"\\nðŸŽ® Ready to begin neural emotion analysis!\")\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
